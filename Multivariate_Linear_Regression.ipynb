{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                            [93, 88, 93],\n",
    "                            [89, 91, 90],\n",
    "                            [96, 98, 100],\n",
    "                            [73, 66, 70]])\n",
    "\n",
    "y_train = torch.FloatTensor([[152], [185], [100], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 초기화\n",
    "model = MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer 설정\n",
    "#설정해주어야 하는, w나 b값이 많아질때, torch.nn을 사용하면, 편리하다.\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 hypothesis: tensor([14.0430, 15.8768, 16.1125, 17.5875, 11.9243]) Cost: 20684.527344\n",
      "Epoch    1/20 hypothesis: tensor([68.7839, 81.6779, 80.9440, 88.1882, 62.1149]) Cost: 7193.705566\n",
      "Epoch    2/20 hypothesis: tensor([ 99.4298, 118.5186, 117.2403, 127.7147,  90.2160]) Cost: 2965.019043\n",
      "Epoch    3/20 hypothesis: tensor([116.5858, 139.1453, 137.5608, 149.8440, 105.9501]) Cost: 1639.521240\n",
      "Epoch    4/20 hypothesis: tensor([126.1893, 150.6945, 148.9370, 162.2332, 114.7602]) Cost: 1224.018311\n",
      "Epoch    5/20 hypothesis: tensor([131.5643, 157.1616, 155.3056, 169.1692, 119.6938]) Cost: 1093.751709\n",
      "Epoch    6/20 hypothesis: tensor([134.5721, 160.7832, 158.8706, 173.0523, 122.4573]) Cost: 1052.890381\n",
      "Epoch    7/20 hypothesis: tensor([136.2545, 162.8119, 160.8661, 175.2261, 124.0056]) Cost: 1040.053345\n",
      "Epoch    8/20 hypothesis: tensor([137.1949, 163.9487, 161.9828, 176.4429, 124.8737]) Cost: 1036.000244\n",
      "Epoch    9/20 hypothesis: tensor([137.7198, 164.5863, 162.6075, 177.1240, 125.3609]) Cost: 1034.700317\n",
      "Epoch   10/20 hypothesis: tensor([138.0122, 164.9442, 162.9567, 177.5051, 125.6349]) Cost: 1034.263916\n",
      "Epoch   11/20 hypothesis: tensor([138.1743, 165.1456, 163.1517, 177.7183, 125.7895]) Cost: 1034.097778\n",
      "Epoch   12/20 hypothesis: tensor([138.2636, 165.2595, 163.2605, 177.8375, 125.8773]) Cost: 1034.016357\n",
      "Epoch   13/20 hypothesis: tensor([138.3120, 165.3242, 163.3208, 177.9040, 125.9277]) Cost: 1033.961670\n",
      "Epoch   14/20 hypothesis: tensor([138.3376, 165.3615, 163.3541, 177.9411, 125.9571]) Cost: 1033.915161\n",
      "Epoch   15/20 hypothesis: tensor([138.3504, 165.3834, 163.3723, 177.9616, 125.9748]) Cost: 1033.871216\n",
      "Epoch   16/20 hypothesis: tensor([138.3560, 165.3967, 163.3819, 177.9729, 125.9859]) Cost: 1033.828613\n",
      "Epoch   17/20 hypothesis: tensor([138.3576, 165.4052, 163.3869, 177.9791, 125.9934]) Cost: 1033.786377\n",
      "Epoch   18/20 hypothesis: tensor([138.3570, 165.4110, 163.3891, 177.9823, 125.9987]) Cost: 1033.743530\n",
      "Epoch   19/20 hypothesis: tensor([138.3551, 165.4153, 163.3899, 177.9840, 126.0030]) Cost: 1033.701294\n",
      "Epoch   20/20 hypothesis: tensor([138.3525, 165.4187, 163.3898, 177.9847, 126.0066]) Cost: 1033.659058\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nb_epochs + 1):\n",
    "    #H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    #cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    #cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(epoch, nb_epochs, prediction.squeeze().detach(), cost.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
